{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XU0_2YOtiCpn"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# ! pip3 install dalex\n","# ! pip install lime\n","! pip install pyexplainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IN2ULQKM2BpT"},"outputs":[],"source":["import csv\n","import numpy as np\n","import pandas as pd\n","from numpy import where\n","from pyexplainer import pyexplainer_pyexplainer\n","from sklearn.datasets import make_classification\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold\n","from sklearn.utils import resample\n","np.random.seed(1)\n","\n","def isfloat(value):\n","  try:\n","    float(value)\n","    return True\n","  except ValueError:\n","    return False\n","\n","def get_rank_diff(list1, list2):\n","  avg_diff = 0\n","  for rd_idx in range(len(list1)):\n","    rank_str = list1[rd_idx]\n","    diff = 0\n","    try:\n","      diff = abs(list2.index(rank_str) - rd_idx)\n","    except ValueError:\n","      diff = len(list1)\n","    avg_diff += diff\n","  return (avg_diff / len(list1))\n","\n","def get_hit_rate(list1, list2):\n","  hr = 0\n","  for str_hr in list1:\n","    if str_hr in list2:\n","      hr += 1\n","  return (hr / len(list1))\n","\n","def parse_rules(input_list, top_n):\n","  parsed_rules = []\n","  for rule in input_list:\n","    for token in rule.split():\n","      if (token not in parsed_rules) and token.isalpha():\n","        parsed_rules.append(token)\n","      if len(parsed_rules) == top_n:\n","        return parsed_rules\n","  return parsed_rules\n","\n","\n","data_list = ['openstack', 'qt']\n","\n","f_write = open('/content/gdrive/MyDrive/XDP/out/pe_lr_vs_rf.csv', 'w')\n","csv_writer = csv.writer(f_write)\n","csv_writer.writerow(['dataset',\n","                     'hit_rate',\n","                     'rank_diff',\n","                     'total',\n","                     'base_shape'])\n","\n","for data_files in data_list:\n","  input_df =  pd.read_csv('/content/gdrive/MyDrive/XDP/dataset/' + data_files + '.csv')\n","  input_df = input_df.drop(['commit_id', 'author_date'], axis=1)\n","  n_fold = 10\n","  kfold = KFold(n_splits=n_fold, shuffle=True, random_state=1)\n","\n","  ########## KFold Loop ##########\n","  for train, test in kfold.split(input_df):\n","    train_data, test_data = input_df.loc[train], input_df.loc[test]\n","    #### Separate x and y for both train and test set ####\n","    train_x = train_data.drop(['bugcount', 'fixcount'], axis=1) \n","    train_real_y = train_data['bugcount']\n","    train_real_y = train_real_y.astype('bool')\n","    feature_names = np.array(list(train_x.columns))\n","\n","    test_x = test_data.drop(['bugcount', 'fixcount'], axis=1)\n","    test_real_y = test_data['bugcount']\n","    test_real_y = test_real_y.astype('bool')\n","\n","    #### apply Spearman Corr based FS on baseline ####\n","    corr_mat = train_x.corr('spearman')\n","    corr_features = set()\n","    for cor_i in range(len(corr_mat.columns)):\n","      for cor_j in range(cor_i):\n","        if abs(corr_mat.iloc[cor_i, cor_j]) > 0.7:\n","          colname = corr_mat.columns[cor_i]\n","          corr_features.add(colname)\n","    \n","    train_x = train_x.drop(labels=corr_features, axis=1)\n","    test_x = test_x.drop(labels=corr_features, axis=1)\n","\n","    # num_of_feature = len(train_x.columns)\n","    num_of_feature = 10\n","\n","    #### Train Classifiers (Logistic Regression) ####\n","    lr = LogisticRegression(random_state=0, solver='liblinear')\n","    lr_pred = lr.fit(train_x, train_real_y).predict(test_x)\n","\n","    rf = RandomForestClassifier(random_state=0)\n","    rf_pred = rf.fit(train_x, train_real_y).predict(test_x)\n","\n","    #### PyExplainer ####\n","    lr_y_preds = pd.DataFrame(data={'bugcount': lr_pred}, index=test_real_y.index)\n","    rf_y_preds = pd.DataFrame(data={'bugcount': rf_pred}, index=test_real_y.index)\n","\n","    lr_combined_testing_data = test_x.join(lr_y_preds)\n","    lr_combined_testing_data.reset_index(inplace=True)\n","    rf_combined_testing_data = test_x.join(rf_y_preds)\n","    rf_combined_testing_data.reset_index(inplace=True)\n","\n","    lr_feature_cols = lr_combined_testing_data.iloc[:, 1:-1]\n","    lr_label_col = lr_combined_testing_data.iloc[:, -1]\n","    rf_feature_cols = rf_combined_testing_data.iloc[:, 1:-1]\n","    rf_label_col = rf_combined_testing_data.iloc[:, -1]\n","\n","    # if nothing predicted as buggy in this fold skip this fold\n","    buggy_cnt = 0\n","    for i, row in lr_combined_testing_data.iterrows():\n","      if lr_combined_testing_data.loc[i]['bugcount'] == True and rf_combined_testing_data.loc[i]['bugcount'] == True:\n","        buggy_cnt += 1\n","    if buggy_cnt == 0:\n","      n_fold -= 1\n","      continue\n","\n","    lr_py_explainer = pyexplainer_pyexplainer.PyExplainer(X_train=train_x,\n","                                                       y_train=train_real_y,\n","                                                       indep=train_x.columns,\n","                                                       dep='bugcount',\n","                                                       blackbox_model=lr)\n","    \n","\n","    rf_py_explainer = pyexplainer_pyexplainer.PyExplainer(X_train=train_x,\n","                                                       y_train=train_real_y,\n","                                                       indep=train_x.columns,\n","                                                       dep='bugcount',\n","                                                       blackbox_model=rf)\n","    \n","\n","    avg_hit_rate = 0\n","    avg_rank_diff = 0\n","    for i, row in lr_combined_testing_data.iterrows():\n","      if lr_combined_testing_data.loc[i]['bugcount'] == True and rf_combined_testing_data.loc[i]['bugcount'] == True:\n","          X_explain = lr_feature_cols.iloc[[i]]\n","          X_explain_rf = rf_feature_cols.iloc[[i]]\n","          y_explain = lr_label_col.iloc[[i]]\n","          y_explain_rf = rf_label_col.iloc[[i]]\n","\n","          rules = lr_py_explainer.explain(X_explain=X_explain,\n","                                       y_explain=y_explain,\n","                                       search_function='crossoverinterpolation')\n","          rules_rf = rf_py_explainer.explain(X_explain=X_explain_rf,\n","                                             y_explain=y_explain_rf,\n","                                             search_function='crossoverinterpolation')\n","\n","          # get hit rate and ranking difference PyExplaner\n","          rank_list_pe = parse_rules(rules['top_k_positive_rules']['rule'].tolist(), num_of_feature)\n","          rank_list_ds_pe = parse_rules(rules_rf['top_k_positive_rules']['rule'].tolist(), num_of_feature)\n","\n","          if not bool(rank_list_pe) or not bool(rank_list_ds_pe):\n","            continue\n","          hit_rate = get_hit_rate(rank_list_pe, rank_list_ds_pe)\n","          rank_diff = get_rank_diff(rank_list_pe, rank_list_ds_pe)\n","\n","          avg_hit_rate += hit_rate\n","          avg_rank_diff += rank_diff\n","\n","    avg_hit_rate /= buggy_cnt\n","    avg_rank_diff /= buggy_cnt\n","\n","    row = [data_files,\n","          avg_hit_rate,\n","          avg_rank_diff,\n","          buggy_cnt,\n","          train_x.shape]\n","    csv_writer.writerow(row)\n","    f_write.flush()\n","    print(row)\n","  ########## End of Bootstrap Loop ##########\n","\n","f_write.close()\n","print('Done!')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"lr_vs_rf.ipynb","provenance":[],"authorship_tag":"ABX9TyP306dujmYBeYXjlE0GA65o"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}