{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cpdpX10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMuj3/ePXc00uOwgSyJF3RV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"xKS3GPOp3MnM"},"source":["! pip3 install dalex\n","! pip install lime\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ip_yBmeE3PpD"},"source":["import csv\n","import dalex as dx\n","import numpy as np\n","import pandas as pd\n","import random\n","import sys\n","from itertools import combinations\n","from lime import lime_tabular\n","from pathlib import Path\n","from sklearn.feature_selection import SelectFpr, chi2\n","from sklearn.linear_model import LogisticRegression\n","np.random.seed(1)\n","\n","def isfloat(value):\n","  try:\n","    float(value)\n","    return True\n","  except ValueError:\n","    return False\n","\n","def get_rank_diff(list1, list2):\n","  avg_diff = 0\n","  for rd_idx in range(len(list1)):\n","    rank_str = list1[rd_idx]\n","    diff = 0\n","    try:\n","      diff = abs(list2.index(rank_str) - rd_idx)\n","    except ValueError:\n","      diff = len(list1)\n","    avg_diff += diff\n","  return (avg_diff / len(list1))\n","\n","def get_hit_rate(list1, list2):\n","  hr = 0\n","  for str_hr in list1:\n","    if str_hr in list2:\n","      hr += 1\n","  return (hr / len(list1))\n","\n","def get_random_train_comp(name_project, list_data):\n","  temp_list = [x for x in list_data if not name_project in x]\n","  return_list = []\n","  for i in range(2):\n","    temp_choice = random.choice(temp_list)\n","    return_list.append(temp_choice)\n","    temp_list.remove(temp_choice)\n","    \n","  return return_list\n","\n","data_list = ['activemq-5.0.0','activemq-5.1.0','activemq-5.2.0','activemq-5.3.0','activemq-5.8.0',\n","             'camel-1.4.0', 'camel-2.9.0','camel-2.10.0','camel-2.11.0',\n","             'derby-10.2.1.6','derby-10.3.1.4','derby-10.5.1.1',\n","             'groovy-1_5_7','groovy-1_6_BETA_1','groovy-1_6_BETA_2',\n","             'hbase-0.94.0','hbase-0.95.0','hbase-0.95.2',\n","             'hive-0.9.0','hive-0.10.0','hive-0.12.0',\n","             'jruby-1.1','jruby-1.4.0','jruby-1.5.0','jruby-1.7.0.preview1',\n","             'lucene-2.3.0','lucene-2.9.0','lucene-3.0.0','lucene-3.1',\n","             'wicket-1.3.0-beta2','wicket-1.3.0-incubating-beta-1','wicket-1.5.3']\n","\n","data_lists = ['wicket-1.3.0-incubating-beta-1','wicket-1.5.3']\n","\n","\n","# exp modes: give custom names in comand-line arguments for different FS algorithms\n","# see Apply Data Feature Selection below\n","\n","f_write = open('/content/gdrive/MyDrive/out/rq5_cpdp_top_10_4.csv', 'w')\n","csv_writer = csv.writer(f_write)\n","csv_writer.writerow(['dataset', 'lime_hit_rate', 'lime_rank_diff', 'dalex_hit_rate', 'dalex_rank_diff', 'base_shape', 'target_shape', 'train1', 'train2'])\n","\n","# iterate through datasets\n","file_cnt = 0\n","while file_cnt < len(data_lists):\n","# for data_files in data_lists:\n","  for ten in range(10):\n","    data_files = data_lists[file_cnt]\n","    print(data_files)\n","    test_df =  pd.read_csv('/content/gdrive/MyDrive/dataset/' + data_files + '.csv')\n","    test_df = test_df.drop('File', axis=1)\n","    test_x_ori = test_df.drop(['HeuBug', 'HeuBugCount', 'RealBug', 'RealBugCount'], axis=1) \n","    test_real_y = test_df['RealBug']\n","    test_real_y = test_real_y.astype('bool')\n","\n","    project_name = data_files.split('-')[0]\n","\n","    train_list = get_random_train_comp(project_name, data_list)\n","    train = train_list[0]\n","    train_comp = train_list[1]\n","\n","    train_df = pd.read_csv('/content/gdrive/MyDrive/dataset/' + train + '.csv')\n","    train_df = train_df.drop('File', axis=1)\n","    train_comp_df = pd.read_csv('/content/gdrive/MyDrive/dataset/' + train_comp + '.csv')\n","    train_comp_df = train_comp_df.drop('File', axis=1)\n","\n","    #### Separate x and y for both train and test set ####\n","    train_x = train_df.drop(['HeuBug', 'HeuBugCount', 'RealBug', 'RealBugCount'], axis=1) \n","    train_real_y = train_df['RealBug']\n","    train_real_y = train_real_y.astype('bool')\n","    feature_names = np.array(list(train_x.columns))\n","\n","    train_comp_x = train_comp_df.drop(['HeuBug', 'HeuBugCount', 'RealBug', 'RealBugCount'], axis=1)\n","    train_comp_real_y = train_comp_df['RealBug']\n","    train_comp_real_y = train_comp_real_y.astype('bool')\n","\n","    #### apply Spearman Corr based FS on baseline ####\n","    corr_mat = train_x.corr('spearman')\n","    corr_features = set()\n","    for cor_i in range(len(corr_mat.columns)):\n","      for cor_j in range(cor_i):\n","        if abs(corr_mat.iloc[cor_i, cor_j]) > 0.7:\n","          colname = corr_mat.columns[cor_i]\n","          corr_features.add(colname)\n","    train_x = train_x.drop(labels=corr_features, axis=1)\n","    test_x = test_x_ori.drop(labels=corr_features, axis=1)\n","\n","    corr_mat_cmp = train_comp_x.corr('spearman')\n","    corr_features_cmp = set()\n","    for cor_i in range(len(corr_mat_cmp.columns)):\n","      for cor_j in range(cor_i):\n","        if abs(corr_mat_cmp.iloc[cor_i, cor_j]) > 0.7:\n","          colname = corr_mat_cmp.columns[cor_i]\n","          corr_features_cmp.add(colname)\n","    train_comp_x = train_comp_x.drop(labels=corr_features_cmp, axis=1)\n","    test_comp_x = test_x_ori.drop(labels=corr_features_cmp, axis=1)\n","    # num_of_feature = len(train_x.columns)\n","    num_of_feature = 10\n","    # print('train_x', train_x.shape)\n","    # print('train_comp_x:', train_comp_x.shape)  \n","\n","    #### Train Classifiers (Logistic Regression) ####\n","    lr = LogisticRegression(random_state=0, solver='liblinear')\n","    lr_pred = lr.fit(train_x, train_real_y).predict(test_x)\n","\n","    lr_fs = LogisticRegression(random_state=0)\n","    lr_fs_pred = lr_fs.fit(train_comp_x, train_comp_real_y).predict(test_comp_x)\n","\n","    # if nothing predicted as buggy in this fold skip this fold\n","    buggy_cnt = 0\n","    for bc in range(len(lr_pred)):\n","      if lr_pred[bc] == True and lr_fs_pred[bc] == True:\n","        buggy_cnt += 1\n","    # print(buggy_cnt)\n","    # buggy_cnt = np.count_nonzero(lr_pred)\n","    if buggy_cnt == 0:\n","      continue\n","\n","    explainer_lime = lime_tabular.LimeTabularExplainer(train_x.to_numpy(),\n","                                    mode='classification',\n","                                    feature_names=train_x.columns.tolist(),\n","                                    discretize_continuous=True,\n","                                    random_state=42)\n","    explainer_lime_fs = lime_tabular.LimeTabularExplainer(train_comp_x.to_numpy(),\n","                                    mode='classification',\n","                                    feature_names=train_comp_x.columns.tolist(),\n","                                    discretize_continuous=True,\n","                                    random_state=42)\n","    exp_dalex = dx.Explainer(lr, train_x, train_real_y, verbose=False)\n","    exp_dalex_fs = dx.Explainer(lr_fs, train_comp_x, train_comp_real_y, verbose=False)\n","\n","    # 'lime_hit_rate', 'lime_rank_diff', 'dalex_hit_rate', 'dalex_rank_diff'\n","    avg_hit_rate_lime = 0\n","    avg_rank_diff_lime = 0\n","    avg_hit_rate_dx = 0\n","    avg_rank_diff_dx = 0\n","    cnt = 0\n","    for i in range(len(lr_pred)):\n","      if lr_pred[i] == True and lr_fs_pred[i] == True:\n","        #### Dalex (BreakDown's new package) ####\n","        # Create explainer for original model\n","        breakdown = exp_dalex.predict_parts(test_x.iloc[i], type='break_down', label=str(i))\n","        # interactions = exp_dalex.predict_parts(test_x.iloc[i], type='break_down_interactions', label=str(i)+'+')\n","        # breakdown.plot(interactions)\n","        result_df = breakdown.result\n","        # print(result_df.iloc[1:].head(top_k_features).to_string)\n","\n","        # Create Explainer for feature selected model\n","        breakdown_fs = exp_dalex_fs.predict_parts(test_comp_x.iloc[i], type='break_down', label=str(i))\n","        # interactions_fs = exp_dalex_fs.predict_parts(test_comp_x.iloc[i], type='break_down_interactions', label=str(i)+'+')\n","        # breakdown_fs.plot(interactions_fs)\n","        result_df_fs = breakdown_fs.result\n","        # print(result_df_fs.iloc[1:].head(top_k_features).to_string)\n","\n","        #### LIME ####\n","        exp_lime = explainer_lime.explain_instance(test_x.to_numpy()[i], lr.predict_proba, num_features=num_of_feature)\n","        lime_result = pd.DataFrame(exp_lime.as_list(), columns=['features','score'])\n","        \n","        exp_lime_fs = explainer_lime_fs.explain_instance(test_comp_x.to_numpy()[i], lr_fs.predict_proba, num_features=num_of_feature)\n","        lime_result_fs = pd.DataFrame(exp_lime_fs.as_list(), columns=['features','score'])\n","\n","        \n","        # get the ranking list of original model (dalex)\n","        rank_list = result_df['variable_name'].tolist()\n","        del rank_list[0]\n","        del rank_list[len(rank_list) - 1]\n","\n","        # get the ranking list of feature selected model (dalex)\n","        rank_list_fs = result_df_fs['variable_name'].tolist()\n","        del rank_list_fs[0]\n","        del rank_list_fs[len(rank_list_fs) - 1]\n","\n","        # get the ranking list of original model (lime)\n","        rank_list_lime = lime_result['features'].tolist()\n","        for k in range(len(rank_list_lime)):\n","          split = rank_list_lime[k].split()\n","          if isfloat(split[0]):\n","            rank_list_lime[k] = split[2]\n","          else:\n","            rank_list_lime[k]= split[0]\n","        # print(rank_list_lime)\n","\n","        # get the ranking list of feature selected model(lime)\n","        rank_list_fs_lime = lime_result_fs['features'].tolist()\n","        for k in range(len(rank_list_fs_lime)):\n","          split = rank_list_fs_lime[k].split()\n","          if isfloat(split[0]):\n","            rank_list_fs_lime[k] = split[2]\n","          else:\n","            rank_list_fs_lime[k]= split[0]\n","        # print(rank_list_fs_lime)\n","\n","        # trunc list for BreakDown\n","        rank_list = rank_list[0:num_of_feature]\n","        rank_list_fs = rank_list_fs[0:num_of_feature]\n","\n","        # get ranking difference for lime and dalex\n","        avg_rank_diff_lime += get_rank_diff(rank_list_lime, rank_list_fs_lime)\n","        avg_rank_diff_dx += get_rank_diff(rank_list, rank_list_fs)\n","\n","        # get hit rate for lime and dalex\n","        avg_hit_rate_lime += get_hit_rate(rank_list_lime, rank_list_fs_lime)\n","        avg_hit_rate_dx += get_hit_rate(rank_list, rank_list_fs)\n","        # print(cnt, '/', buggy_cnt)\n","        cnt += 1\n","    avg_hit_rate_lime /= buggy_cnt\n","    avg_rank_diff_lime /= buggy_cnt\n","    avg_hit_rate_dx /= buggy_cnt\n","    avg_rank_diff_dx /= buggy_cnt\n","    row = [data_files, avg_hit_rate_lime, avg_rank_diff_lime, avg_hit_rate_dx, avg_rank_diff_dx, train_x.shape, train_comp_x.shape, train, train_comp]\n","    csv_writer.writerow(row)\n","    print(row)\n","    f_write.flush()\n","  file_cnt += 1\n","f_write.close()\n","print('Done!')"],"execution_count":null,"outputs":[]}]}