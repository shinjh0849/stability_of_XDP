{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RandomUnderSampling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5ZFlchqB60pC/P287wc4B"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"0CKhETsCwJ5q"},"source":["! pip3 install dalex\n","! pip install lime\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60xUBQZc0cu5"},"source":["import csv\n","import dalex as dx\n","import numpy as np\n","import pandas as pd\n","from imblearn.under_sampling import RandomUnderSampler \n","from lime import lime_tabular\n","from numpy import where\n","from sklearn.datasets import make_classification\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold\n","from sklearn.utils import resample\n","np.random.seed(1)\n","\n","def isfloat(value):\n","  try:\n","    float(value)\n","    return True\n","  except ValueError:\n","    return False\n","\n","def get_rank_diff(list1, list2):\n","  avg_diff = 0\n","  for rd_idx in range(len(list1)):\n","    rank_str = list1[rd_idx]\n","    diff = 0\n","    try:\n","      diff = abs(list2.index(rank_str) - rd_idx)\n","    except ValueError:\n","      diff = len(list1)\n","    avg_diff += diff\n","  return (avg_diff / len(list1))\n","\n","def get_hit_rate(list1, list2):\n","  hr = 0\n","  for str_hr in list1:\n","    if str_hr in list2:\n","      hr += 1\n","  return (hr / len(list1))\n","\n","data_list = ['activemq-5.0.0','activemq-5.1.0','activemq-5.2.0','activemq-5.3.0','activemq-5.8.0',\n","             'camel-1.4.0', 'camel-2.9.0','camel-2.10.0','camel-2.11.0',\n","             'derby-10.2.1.6','derby-10.3.1.4','derby-10.5.1.1',\n","             'groovy-1_5_7','groovy-1_6_BETA_1','groovy-1_6_BETA_2',\n","             'hbase-0.94.0','hbase-0.95.0','hbase-0.95.2',\n","             'hive-0.9.0','hive-0.10.0','hive-0.12.0',\n","             'jruby-1.1','jruby-1.4.0','jruby-1.5.0','jruby-1.7.0.preview1',\n","             'lucene-2.3.0','lucene-2.9.0','lucene-3.0.0','lucene-3.1',\n","             'wicket-1.3.0-beta2','wicket-1.3.0-incubating-beta-1','wicket-1.5.3']\n","\n","\n","f_write = open('/content/gdrive/MyDrive/out/rq2_rus_top_15.csv', 'w')\n","csv_writer = csv.writer(f_write)\n","csv_writer.writerow(['dataset', 'lime_hit_rate', 'lime_rank_diff', 'dalex_hit_rate', 'dalex_rank_diff', 'lime_order', 'dalex_order', 'total', 'base_shape', 'target_shape'])\n","\n","for data_files in data_list:\n","  print(data_files)\n","  input_df =  pd.read_csv('/content/gdrive/MyDrive/dataset/' + data_files + '.csv')\n","  input_df = input_df.drop('File', axis=1)\n","  n_fold = 10\n","  kfold = KFold(n_fold, True, 1)\n","\n","  ########## KFold Loop ##########\n","  for train, test in kfold.split(input_df):\n","    train_data, test_data = input_df.loc[train], input_df.loc[test]\n","    #### Separate x and y for both train and test set ####\n","    train_x = train_data.drop(['HeuBug', 'HeuBugCount', 'RealBug', 'RealBugCount'], axis=1) \n","    train_real_y = train_data['RealBug']\n","    train_real_y = train_real_y.astype('bool')\n","    feature_names = np.array(list(train_x.columns))\n","\n","    test_x = test_data.drop(['HeuBug', 'HeuBugCount', 'RealBug', 'RealBugCount'], axis=1)\n","    test_real_y = test_data['RealBug']\n","    test_real_y = test_real_y.astype('bool')\n","\n","    #### apply Spearman Corr based FS on baseline ####\n","    corr_mat = train_x.corr('spearman')\n","    corr_features = set()\n","    for cor_i in range(len(corr_mat.columns)):\n","      for cor_j in range(cor_i):\n","        if abs(corr_mat.iloc[cor_i, cor_j]) > 0.7:\n","          colname = corr_mat.columns[cor_i]\n","          corr_features.add(colname)\n","    \n","    train_x = train_x.drop(labels=corr_features, axis=1)\n","    test_x = test_x.drop(labels=corr_features, axis=1)\n","\n","    # num_of_feature = len(train_x.columns)\n","    num_of_feature = 15\n","\n","    #### Apply Data Sampling Method ####\n","    data_sampler = RandomUnderSampler(random_state=42)\n","    data_sampled_x, data_sampled_y = data_sampler.fit_resample(train_x, train_real_y)\n","    data_sampled_x = pd.DataFrame(data_sampled_x, columns=train_x.columns)\n","\n","    #### Train Classifiers (Logistic Regression) ####\n","    lr = LogisticRegression(random_state=0, solver='liblinear')\n","    lr_pred = lr.fit(train_x, train_real_y).predict(test_x)\n","\n","    lr_ds = LogisticRegression(random_state=0)\n","    lr_ds_pred = lr_ds.fit(data_sampled_x, data_sampled_y).predict(test_x)\n","\n","    # if nothing predicted as buggy in this fold skip this fold\n","    # buggy_cnt = np.count_nonzero(lr_pred)\n","    buggy_cnt = 0\n","    for bc in range(len(lr_pred)):\n","      if lr_pred[bc] == True and lr_ds_pred[bc] == True:\n","        buggy_cnt += 1\n","    if buggy_cnt == 0:\n","      n_fold -= 1\n","      continue\n","\n","    explainer_lime = lime_tabular.LimeTabularExplainer(train_x.to_numpy(),\n","                                    mode='classification',\n","                                    feature_names=train_x.columns.tolist(),\n","                                    discretize_continuous=True,\n","                                    random_state=42)\n","    explainer_lime_ds = lime_tabular.LimeTabularExplainer(data_sampled_x.to_numpy(),\n","                                    mode='classification',\n","                                    feature_names=data_sampled_x.columns.tolist(),\n","                                    discretize_continuous=True,\n","                                    random_state=42)\n","    \n","    exp_dalex = dx.Explainer(lr, train_x, train_real_y, verbose=False)\n","\n","    exp_dalex_ds = dx.Explainer(lr_ds, data_sampled_x, data_sampled_y, verbose=False)\n","\n","    avg_hit_rate_lime = 0\n","    avg_rank_diff_lime = 0\n","    avg_hit_rate_dx = 0\n","    avg_rank_diff_dx = 0\n","    avg_order_lime = 0\n","    avg_order_dx = 0\n","    cnt = 0\n","    for i in range(len(lr_pred)):\n","      if lr_pred[i] == True and lr_ds_pred[i] == True:\n","        #### Dalex (BreakDown's new package) ####\n","        # Create explainer for original model\n","        breakdown = exp_dalex.predict_parts(test_x.iloc[i], type='break_down', label=str(i))\n","        # interactions = exp_dalex.predict_parts(test_x.iloc[i], type='break_down_interactions', label=str(i)+'+')\n","        # breakdown.plot(interactions)\n","        result_df = breakdown.result\n","        # print(result_df.iloc[1:].head(top_k_features).to_string)\n","\n","        # Create Explainer for data sampled model\n","        breakdown_ds = exp_dalex_ds.predict_parts(test_x.iloc[i], type='break_down', label=str(i))\n","        # interactions_ds = exp_dalex_ds.predict_parts(test_x.iloc[i], type='break_down_interactions', label=str(i)+'+')\n","        # breakdown_ds.plot(interactions_ds)\n","        result_df_ds = breakdown_ds.result\n","        # print(result_df_ds.iloc[1:].head(top_k_features).to_string)\n","\n","        #### LIME ####\n","        exp_lime = explainer_lime.explain_instance(test_x.to_numpy()[i], lr.predict_proba, num_features=num_of_feature)\n","        lime_result = pd.DataFrame(exp_lime.as_list(), columns=['features','score'])\n","        \n","        exp_lime_ds = explainer_lime_ds.explain_instance(test_x.to_numpy()[i], lr_ds.predict_proba, num_features=num_of_feature)\n","        lime_result_ds = pd.DataFrame(exp_lime_ds.as_list(), columns=['features','score'])\n","\n","        # get the ranking list of original model (dalex)\n","        rank_list = result_df['variable_name'].tolist()\n","        del rank_list[0]\n","        del rank_list[len(rank_list) - 1]\n","\n","        # get the ranking list of data sampled model (dalex)\n","        rank_list_ds = result_df_ds['variable_name'].tolist()\n","        del rank_list_ds[0]\n","        del rank_list_ds[len(rank_list_ds) - 1]\n","\n","        # get the ranking list of original model (lime)\n","        rank_list_lime = lime_result['features'].tolist()\n","        for k in range(len(rank_list_lime)):\n","          split = rank_list_lime[k].split()\n","          if isfloat(split[0]):\n","            rank_list_lime[k] = split[2]\n","          else:\n","            rank_list_lime[k]= split[0]\n","        # print(rank_list_lime)\n","\n","        # get the ranking list of data sampled model(lime)\n","        rank_list_ds_lime = lime_result_ds['features'].tolist()\n","        for k in range(len(rank_list_ds_lime)):\n","          split = rank_list_ds_lime[k].split()\n","          if isfloat(split[0]):\n","            rank_list_ds_lime[k] = split[2]\n","          else:\n","            rank_list_ds_lime[k]= split[0]\n","        # print(rank_list_ds_lime)\n","\n","        # trunc list for BreakDown\n","        rank_list = rank_list[0:num_of_feature]\n","        rank_list_ds = rank_list_ds[0:num_of_feature]\n","\n","        # get ranking difference for dalex and lime\n","        avg_rank_diff_lime += get_rank_diff(rank_list_lime, rank_list_ds_lime)\n","        avg_rank_diff_dx += get_rank_diff(rank_list, rank_list_ds)\n","\n","        # get hit rate for lime only for RQ2. (RQ1 needs for dx too)\n","        avg_hit_rate_lime += get_hit_rate(rank_list_lime, rank_list_ds_lime)\n","        avg_hit_rate_dx += get_hit_rate(rank_list, rank_list_ds)\n","\n","        # get number of instances that has the same order for both LIME and BreakDown\n","        if get_rank_diff(rank_list_lime, rank_list_ds_lime) == 0:\n","          avg_order_lime += 1\n","        if get_rank_diff(rank_list, rank_list_ds) == 0:\n","          avg_order_dx +=1\n","\n","\n","        # print(cnt, '/', buggy_cnt)\n","        cnt += 1\n","\n","    avg_rank_diff_dx /= buggy_cnt\n","    avg_rank_diff_lime /= buggy_cnt\n","    avg_hit_rate_dx /= buggy_cnt\n","    avg_hit_rate_lime /= buggy_cnt\n","    avg_order_lime /= buggy_cnt\n","    avg_order_dx /= buggy_cnt\n","    row = [data_files, avg_hit_rate_lime, avg_rank_diff_lime, avg_hit_rate_dx, avg_rank_diff_dx, avg_order_lime, avg_order_dx, buggy_cnt, train_x.shape, data_sampled_x.shape]\n","    csv_writer.writerow(row)\n","    f_write.flush()\n","    print(row)\n","  ########## End of Bootstrap Loop ##########\n","\n","f_write.close()\n","print('Done!')"],"execution_count":null,"outputs":[]}]}