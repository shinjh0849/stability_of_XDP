{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Lc8n7nIb3xen"},"outputs":[],"source":["! pip3 install dalex\n","! pip3 install lime\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MZz6maXm31h3"},"outputs":[],"source":["import csv\n","import dalex as dx\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","from lime import lime_tabular\n","from sklearn_pandas import DataFrameMapper\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import KFold\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import LabelBinarizer, StandardScaler, LabelEncoder\n","from sklearn.metrics import accuracy_score\n","\n","np.random.seed(1)\n","\n","def xgb_prediction(X_array_in):\n","    if len(X_array_in.shape) < 2:\n","        X_array_in = np.expand_dims(X_array_in, 0)\n","    return model.predict_proba(X_array_in)\n","\n","def isfloat(value):\n","  try:\n","    float(value)\n","    return True\n","  except ValueError:\n","    return False\n","\n","def get_rank_diff(list1, list2):\n","  avg_diff = 0\n","  for rd_idx in range(len(list1)):\n","    rank_str = list1[rd_idx]\n","    diff = 0\n","    try:\n","      diff = abs(list2.index(rank_str) - rd_idx)\n","    except ValueError:\n","      diff = len(list1)\n","    avg_diff += diff\n","  return (avg_diff / len(list1))\n","\n","def get_hit_rate(list1, list2):\n","  hr = 0\n","  for str_hr in list1:\n","    if str_hr in list2:\n","      hr += 1\n","  return (hr / len(list1))\n","\n","\n","data_list = ['activemq-5.0.0','activemq-5.1.0','activemq-5.2.0','activemq-5.3.0','activemq-5.8.0',\n","             'camel-1.4.0', 'camel-2.9.0','camel-2.10.0','camel-2.11.0',\n","             'derby-10.2.1.6','derby-10.3.1.4','derby-10.5.1.1',\n","             'groovy-1_5_7','groovy-1_6_BETA_1','groovy-1_6_BETA_2',\n","             'hbase-0.94.0','hbase-0.95.0','hbase-0.95.2',\n","             'hive-0.9.0','hive-0.10.0','hive-0.12.0',\n","             'jruby-1.1','jruby-1.4.0','jruby-1.5.0','jruby-1.7.0.preview1',\n","             'lucene-2.3.0','lucene-2.9.0','lucene-3.0.0','lucene-3.1',\n","             'wicket-1.3.0-beta2','wicket-1.3.0-incubating-beta-1','wicket-1.5.3']\n","\n","\n","\n","f_write = open('/content/gdrive/MyDrive/out/rq3_xgb_top_10.csv', 'w')\n","csv_writer = csv.writer(f_write)\n","csv_writer.writerow(['dataset', 'lime_hit_rate', 'lime_rank_diff', 'dalex_hit_rate', 'dalex_rank_diff', 'base_shape', 'target_shape'])\n","\n","for data_files in data_list:\n","  print(data_files)\n","  input_df =  pd.read_csv('/content/gdrive/MyDrive/dataset/' + data_files + '.csv')\n","  input_df = input_df.drop('File', axis=1)\n","  n_fold = 10\n","  kfold = KFold(n_fold, True, 1)\n","\n","  ########## KFold Loop ##########\n","  for train, test in kfold.split(input_df):\n","    train_data, test_data = input_df.loc[train], input_df.loc[test]\n","    #### Separate x and y for both train and test set ####\n","    train_x = train_data.drop(['HeuBug', 'HeuBugCount', 'RealBug', 'RealBugCount'], axis=1) \n","    train_real_y = train_data['RealBug']\n","    train_real_y = train_real_y.astype('bool')\n","    test_x = test_data.drop(['HeuBug', 'HeuBugCount', 'RealBug', 'RealBugCount'], axis=1)\n","    test_real_y = test_data['RealBug']\n","    test_real_y = test_real_y.astype('bool')\n","\n","    #### apply Spearman Corr based FS on baseline ####\n","    corr_mat = train_x.corr('spearman')\n","    corr_features = set()\n","    for cor_i in range(len(corr_mat.columns)):\n","      for cor_j in range(cor_i):\n","        if abs(corr_mat.iloc[cor_i, cor_j]) > 0.7:\n","          colname = corr_mat.columns[cor_i]\n","          corr_features.add(colname)\n","\n","    train_x = train_x.drop(labels=corr_features, axis=1)\n","    test_x = test_x.drop(labels=corr_features, axis=1)\n","\n","    feature_names = np.array(list(train_x.columns))\n","    # num_of_feature = len(train_x.columns)\n","    num_of_feature = 10\n","    #### Train Classifiers (Logistic Regression) ####\n","    lr = LogisticRegression(random_state=0, solver='liblinear')\n","    lr_pred = lr.fit(train_x, train_real_y).predict(test_x)\n","\n","    #### Apply Different ML algorithms ####\n","    # ml = XGBClassifier(n_estimators=300, max_depth=5)\n","    # ml_pred = ml.fit(train_map, train_real_y).predict(test_map)\n","    # predict_fn = lambda x: ml.predict_proba(mapper.fit_transform(x))\n","    ml = Pipeline([('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n","                         ('model', XGBClassifier())])\n","    ml.fit(train_x, train_real_y)\n","    ml_pred = ml.predict(test_x)\n","    # print(ml_pred)\n","\n","    buggy_cnt = 0\n","    for bc in range(len(lr_pred)):\n","        if (lr_pred[bc] == True) and (ml_pred[bc] == True):\n","            buggy_cnt += 1\n","    if buggy_cnt == 0:\n","      n_fold -= 1\n","      continue\n","\n","    # explainer_lime = lime_tabular.LimeTabularExplainer(train_x.to_numpy(),\n","    #                                 mode='classification',\n","    #                                 feature_names=train_x.columns.values.tolist(),\n","    #                                 discretize_continuous=True,\n","    #                                 random_state=42)\n","  \n","    X_train_imputed = ml.named_steps['imputer'].transform(train_x)\n","    explainer_lime = lime_tabular.LimeTabularExplainer(X_train_imputed, \n","        feature_names=train_x.columns.tolist(),\n","        mode='classification',\n","        random_state=42,\n","        discretize_continuous=True)\n","\n","    model = ml.named_steps['model']\n","    X_test_imputed = ml.named_steps['imputer'].transform(test_x)\n","\n","\n","    exp_dalex = dx.Explainer(lr, train_x, train_real_y, verbose=False)\n","\n","    exp_dalex_ds = dx.Explainer(ml, train_x, train_real_y, verbose=False)\n","\n","    avg_hit_rate_lime = 0\n","    avg_rank_diff_lime = 0\n","    avg_hit_rate_dx = 0\n","    avg_rank_diff_dx = 0\n","    cnt = 0\n","    for i in range(len(lr_pred)):\n","      if (lr_pred[i] == True) and (ml_pred[i] == True):\n","        #### Dalex (BreakDown's new package) ####\n","        # Create explainer for original model\n","        breakdown = exp_dalex.predict_parts(test_x.iloc[i], type='break_down', label=str(i))\n","        # interactions = exp_dalex.predict_parts(test_x.iloc[i], type='break_down_interactions', label=str(i)+'+')\n","        # breakdown.plot(interactions)\n","        result_df = breakdown.result\n","\n","        # Create Explainer for data sampled model\n","        breakdown_ds = exp_dalex_ds.predict_parts(X_test_imputed[i], type='break_down', label=str(i))\n","        # interactions_ds = exp_dalex_ds.predict_parts(test_x.iloc[i], type='break_down_interactions', label=str(i)+'+')\n","        # breakdown_ds.plot(interactions_ds)\n","        result_df_ds = breakdown_ds.result\n","\n","        #### LIME ####\n","        exp_lime = explainer_lime.explain_instance(test_x.to_numpy()[i], lr.predict_proba, num_features=num_of_feature)\n","        lime_result = pd.DataFrame(exp_lime.as_list(), columns=['features','score'])\n","        exp_lime_ds = explainer_lime.explain_instance(X_test_imputed[i], xgb_prediction, num_features=num_of_feature)\n","        lime_result_ds = pd.DataFrame(exp_lime_ds.as_list(), columns=['features','score'])\n","\n","        # get the ranking list of original model (dalex)\n","        rank_list = result_df['variable_name'].tolist()\n","        del rank_list[0]\n","        del rank_list[len(rank_list) - 1]\n","\n","        # get the ranking list of data sampled model (dalex)\n","        rank_list_ds = result_df_ds['variable_name'].tolist()\n","        del rank_list_ds[0]\n","        del rank_list_ds[len(rank_list_ds) - 1]\n","\n","        # get the ranking list of original model (lime)\n","        rank_list_lime = lime_result['features'].tolist()\n","        for k in range(len(rank_list_lime)):\n","          split = rank_list_lime[k].split()\n","          if isfloat(split[0]):\n","            rank_list_lime[k] = split[2]\n","          else:\n","            rank_list_lime[k]= split[0]\n","\n","        # get the ranking list of data sampled model(lime)\n","        rank_list_ds_lime = lime_result_ds['features'].tolist()\n","        for k in range(len(rank_list_ds_lime)):\n","          split = rank_list_ds_lime[k].split()\n","          if isfloat(split[0]):\n","            rank_list_ds_lime[k] = split[2]\n","          else:\n","            rank_list_ds_lime[k]= split[0]\n","\n","        # trunc list for BreakDown\n","        rank_list = rank_list[0:num_of_feature]\n","        rank_list_ds = rank_list_ds[0:num_of_feature]\n","\n","        # get ranking difference for dalex and lime\n","        avg_rank_diff_lime += get_rank_diff(rank_list_lime, rank_list_ds_lime)\n","        avg_rank_diff_dx += get_rank_diff(rank_list, rank_list_ds)\n","\n","        # get hit rate for lime only for RQ2. (RQ1 needs for dx too)\n","        avg_hit_rate_lime += get_hit_rate(rank_list_lime, rank_list_ds_lime)\n","        avg_hit_rate_dx += get_hit_rate(rank_list, rank_list_ds)\n","\n","        cnt += 1\n","\n","    avg_rank_diff_dx /= buggy_cnt\n","    avg_rank_diff_lime /= buggy_cnt\n","    avg_hit_rate_dx /= buggy_cnt\n","    avg_hit_rate_lime /= buggy_cnt\n","    row = [data_files, avg_hit_rate_lime, avg_rank_diff_lime, avg_hit_rate_dx, avg_rank_diff_dx, train_x.shape, train_x.shape]\n","    csv_writer.writerow(row)\n","    f_write.flush()\n","    print(row)\n","\n","  ########## End of KFold Loop ##########\n","\n","f_write.close()\n","print('Done!')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"xgb.ipynb","provenance":[],"authorship_tag":"ABX9TyMC4FumOk+hglczqVhlVLh/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}